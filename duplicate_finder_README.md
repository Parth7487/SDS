# Duplicate Image Finder Tools

This repository contains two Python scripts for finding duplicate images in your gallery or any directory:

## Tools Overview

### 1. `simple_duplicate_finder.py` (Recommended for most users)
- **No external dependencies** - uses only Python standard library
- Finds **exact duplicates** using MD5 file hash comparison
- Fast and efficient with file size pre-filtering
- Generates cleanup recommendations and scripts
- Works immediately on any system with Python 3.6+

### 2. `duplicate_image_finder.py` (Advanced features)
- Requires external dependencies (PIL, imagehash, scikit-image)
- Finds **exact duplicates** AND **similar images**
- Uses multiple detection methods:
  - File hash comparison (exact duplicates)
  - Perceptual hashing (similar images)
  - Structural similarity (SSIM)
- More comprehensive but requires setup

## Quick Start

### For immediate use (no setup required):
```bash
python3 simple_duplicate_finder.py /path/to/your/gallery
```

### For advanced features (requires pip install):
```bash
pip install -r requirements.txt
python3 duplicate_image_finder.py /path/to/your/gallery
```

## Installation

### Simple Tool (No Installation Required)
The `simple_duplicate_finder.py` script works out of the box with any Python 3.6+ installation.

### Advanced Tool
1. Install dependencies:
   ```bash
   pip install -r requirements.txt
   ```
   
   Or manually:
   ```bash
   pip install Pillow imagehash scikit-image numpy
   ```

2. Run the advanced tool:
   ```bash
   python3 duplicate_image_finder.py
   ```

## Usage Examples

### Basic Usage
```bash
# Scan current directory
python3 simple_duplicate_finder.py

# Scan specific directory
python3 simple_duplicate_finder.py /home/user/Pictures

# Scan with custom output file
python3 simple_duplicate_finder.py ~/Gallery --output my_results.json

# Don't generate cleanup script
python3 simple_duplicate_finder.py ~/Photos --no-script
```

### Advanced Usage
```bash
# Use advanced similarity detection
python3 duplicate_image_finder.py ~/Pictures

# Adjust similarity threshold (0.0-1.0, default 0.9)
python3 duplicate_image_finder.py ~/Pictures --similarity 0.85

# Custom output file
python3 duplicate_image_finder.py ~/Pictures --output advanced_results.json
```

## What Each Tool Finds

### Simple Duplicate Finder
- **Exact duplicates only**: Files with identical content (same MD5 hash)
- Perfect for finding true duplicates (same image copied multiple times)
- Examples of what it finds:
  - `IMG_001.jpg` and `IMG_001_copy.jpg` (exact same file)
  - `photo.png` and `photo_backup.png` (identical content)

### Advanced Duplicate Finder
- **Exact duplicates**: Same as simple tool
- **Similar images**: Visually similar but not identical
- **Structural similarity**: Images with similar composition
- Examples of additional matches:
  - Same photo in different formats (JPG vs PNG)
  - Images with slight compression differences
  - Photos with minor edits (brightness, contrast)
  - Resized versions of the same image

## Output Files

Both tools generate several output files:

### 1. JSON Report (`duplicate_images_report.json`)
Contains detailed analysis including:
- Scan information (directory, timestamp, totals)
- Duplicate groups with file paths and hashes
- Recommendations for which files to keep/delete
- Space savings calculations

### 2. Cleanup Script (`cleanup_duplicates.sh`)
Generated by the simple tool:
- Bash script to automatically delete recommended duplicates
- **Review carefully before running!**
- Makes the script executable automatically
- Includes safety checks and progress output

Example cleanup script usage:
```bash
# Review the generated script first
cat cleanup_duplicates.sh

# Run it (after careful review)
./cleanup_duplicates.sh
```

## Sample Output

```
Simple Duplicate Image Finder
==================================================
Starting duplicate image scan...
Scanning directory: /home/user/Pictures
Found 1,234 image files
Finding exact duplicates...
Grouping files by size...
Found 89 files with duplicate sizes
Calculating hashes for 89 potential duplicates...

============================================================
DUPLICATE IMAGE ANALYSIS RESULTS
============================================================
Directory scanned: /home/user/Pictures
Duplicate groups found: 12
Total duplicate files: 23
Total wasted space: 45.67 MB

============================================================
DUPLICATE GROUPS
============================================================

Group 1 (3 files, Hash: a1b2c3d4...):
  1. /home/user/Pictures/vacation/beach.jpg
     Size: 2.3 MB, Modified: 2024-01-15 14:30:22
  2. /home/user/Pictures/backup/beach.jpg
     Size: 2.3 MB, Modified: 2024-01-10 09:15:33
  3. /home/user/Pictures/beach_copy.jpg
     Size: 2.3 MB, Modified: 2024-01-08 11:22:44

============================================================
RECOMMENDATIONS
============================================================

Group 1:
  KEEP: /home/user/Pictures/vacation/beach.jpg
  DELETE (2 files):
    - /home/user/Pictures/backup/beach.jpg
    - /home/user/Pictures/beach_copy.jpg
  Space saved: 4.6 MB
```

## Supported Image Formats

Both tools support these image formats:
- **JPG/JPEG** (.jpg, .jpeg)
- **PNG** (.png)
- **GIF** (.gif)
- **BMP** (.bmp)
- **WEBP** (.webp)
- **TIFF** (.tiff, .tif)
- **SVG** (.svg)
- **ICO** (.ico)

## How Duplicate Detection Works

### File Hash Method (Both Tools)
1. **Size Filtering**: First groups files by size for efficiency
2. **Hash Calculation**: Calculates MD5 hash for files with duplicate sizes
3. **Exact Matching**: Files with identical hashes are exact duplicates

### Perceptual Hash Method (Advanced Tool Only)
1. **Image Processing**: Converts images to standard format
2. **Hash Generation**: Creates perceptual fingerprints using multiple algorithms:
   - Average hash (aHash)
   - Difference hash (dHash)
   - Perceptual hash (pHash)
   - Wavelet hash (wHash)
3. **Similarity Comparison**: Compares hash distances to find similar images

### Structural Similarity Method (Advanced Tool Only)
1. **Image Normalization**: Resizes images to standard dimensions
2. **SSIM Calculation**: Uses Structural Similarity Index Measure
3. **Threshold Matching**: Groups images above similarity threshold

## Cleanup Recommendations

The tools use smart logic to recommend which files to keep:

1. **Newest files first**: Keeps the most recently modified version
2. **Shorter paths**: Prefers files in less nested directories
3. **Larger files**: When timestamps are equal, keeps the larger file

You can always manually review and modify the recommendations before running any cleanup scripts.

## Performance Notes

### Simple Tool
- **Fast**: Can process thousands of images in seconds
- **Memory efficient**: Processes files incrementally
- **No size limits**: Handles large galleries efficiently

### Advanced Tool
- **Moderate speed**: Perceptual hashing adds processing time
- **Memory usage**: Higher due to image processing
- **Size limits**: Structural similarity limited to 500 images for performance

## Safety Features

- **No automatic deletion**: Tools only recommend, never delete automatically
- **Backup recommendations**: Always suggests keeping the "best" version
- **Review scripts**: Generated cleanup scripts can be reviewed before execution
- **Error handling**: Graceful handling of corrupted files or permission issues
- **Progress reporting**: Shows progress for large galleries

## Troubleshooting

### Common Issues

1. **Permission Denied**: Make sure you have read access to the directory
2. **No images found**: Check that the directory path is correct
3. **Memory errors**: For very large galleries, use the simple tool instead

### Getting Help

Run with `--help` flag for usage information:
```bash
python3 simple_duplicate_finder.py --help
python3 duplicate_image_finder.py --help
```

## Use Cases

### Home Photo Management
- Clean up downloaded photos with duplicates
- Organize family photo collections
- Remove backup copies taking up space

### Professional Photography
- Manage large RAW + JPEG collections
- Find similar shots from photo sessions
- Clean up processed image folders

### Digital Asset Management
- Audit image databases for duplicates
- Prepare images for archiving
- Optimize storage usage

## Advanced Tips

1. **Batch Processing**: Process subdirectories separately for better control
2. **Backup First**: Always backup your photos before running cleanup scripts
3. **Test Small**: Try on a small directory first to understand the output
4. **Custom Thresholds**: Adjust similarity thresholds based on your needs
5. **Review Results**: Always manually review recommendations before deletion

## Limitations

### Simple Tool
- Only finds exact duplicates
- Cannot detect resized or edited versions
- Limited to file-level comparison

### Advanced Tool
- Requires additional dependencies
- Slower processing for similar image detection
- May have false positives with very similar but different images

## Contributing

Feel free to suggest improvements or report issues. The tools are designed to be:
- Safe (no accidental deletions)
- Fast (efficient processing)
- Comprehensive (detailed reporting)
- User-friendly (clear output and recommendations)